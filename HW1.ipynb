{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tagline\": \"You Know, for Search\",\n",
      "  \"cluster_name\": \"TwitterDB\",\n",
      "  \"name\": \"Machine1\",\n",
      "  \"version\": {\n",
      "    \"build_timestamp\": \"2014-12-16T14:11:12Z\",\n",
      "    \"lucene_version\": \"4.10.2\",\n",
      "    \"number\": \"1.4.2\",\n",
      "    \"build_snapshot\": false,\n",
      "    \"build_hash\": \"927caff6f05403e936c20bf4529f144f0c89fd8c\"\n",
      "  },\n",
      "  \"status\": 200\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch()\n",
    "print (json.dumps(es.info(),indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Elasticsearch in module elasticsearch.client:\n",
      "\n",
      "class Elasticsearch(builtins.object)\n",
      " |  Elasticsearch low-level client. Provides a straightforward mapping from\n",
      " |  Python to ES REST endpoints.\n",
      " |  \n",
      " |  The instance has attributes ``cat``, ``cluster``, ``indices``, ``ingest``,\n",
      " |  ``nodes``, ``snapshot`` and ``tasks`` that provide access to instances of\n",
      " |  :class:`~elasticsearch.client.CatClient`,\n",
      " |  :class:`~elasticsearch.client.ClusterClient`,\n",
      " |  :class:`~elasticsearch.client.IndicesClient`,\n",
      " |  :class:`~elasticsearch.client.IngestClient`,\n",
      " |  :class:`~elasticsearch.client.NodesClient`,\n",
      " |  :class:`~elasticsearch.client.SnapshotClient` and\n",
      " |  :class:`~elasticsearch.client.TasksClient` respectively. This is the\n",
      " |  preferred (and only supported) way to get access to those classes and their\n",
      " |  methods.\n",
      " |  \n",
      " |  You can specify your own connection class which should be used by providing\n",
      " |  the ``connection_class`` parameter::\n",
      " |  \n",
      " |      # create connection to localhost using the ThriftConnection\n",
      " |      es = Elasticsearch(connection_class=ThriftConnection)\n",
      " |  \n",
      " |  If you want to turn on :ref:`sniffing` you have several options (described\n",
      " |  in :class:`~elasticsearch.Transport`)::\n",
      " |  \n",
      " |      # create connection that will automatically inspect the cluster to get\n",
      " |      # the list of active nodes. Start with nodes running on 'esnode1' and\n",
      " |      # 'esnode2'\n",
      " |      es = Elasticsearch(\n",
      " |          ['esnode1', 'esnode2'],\n",
      " |          # sniff before doing anything\n",
      " |          sniff_on_start=True,\n",
      " |          # refresh nodes after a node fails to respond\n",
      " |          sniff_on_connection_fail=True,\n",
      " |          # and also every 60 seconds\n",
      " |          sniffer_timeout=60\n",
      " |      )\n",
      " |  \n",
      " |  Different hosts can have different parameters, use a dictionary per node to\n",
      " |  specify those::\n",
      " |  \n",
      " |      # connect to localhost directly and another node using SSL on port 443\n",
      " |      # and an url_prefix. Note that ``port`` needs to be an int.\n",
      " |      es = Elasticsearch([\n",
      " |          {'host': 'localhost'},\n",
      " |          {'host': 'othernode', 'port': 443, 'url_prefix': 'es', 'use_ssl': True},\n",
      " |      ])\n",
      " |  \n",
      " |  If using SSL, there are several parameters that control how we deal with\n",
      " |  certificates (see :class:`~elasticsearch.Urllib3HttpConnection` for\n",
      " |  detailed description of the options)::\n",
      " |  \n",
      " |      es = Elasticsearch(\n",
      " |          ['localhost:443', 'other_host:443'],\n",
      " |          # turn on SSL\n",
      " |          use_ssl=True,\n",
      " |          # make sure we verify SSL certificates (off by default)\n",
      " |          verify_certs=True,\n",
      " |          # provide a path to CA certs on disk\n",
      " |          ca_certs='/path/to/CA_certs'\n",
      " |      )\n",
      " |  \n",
      " |  SSL client authentication is supported\n",
      " |  (see :class:`~elasticsearch.Urllib3HttpConnection` for\n",
      " |  detailed description of the options)::\n",
      " |  \n",
      " |      es = Elasticsearch(\n",
      " |          ['localhost:443', 'other_host:443'],\n",
      " |          # turn on SSL\n",
      " |          use_ssl=True,\n",
      " |          # make sure we verify SSL certificates (off by default)\n",
      " |          verify_certs=True,\n",
      " |          # provide a path to CA certs on disk\n",
      " |          ca_certs='/path/to/CA_certs',\n",
      " |          # PEM formatted SSL client certificate\n",
      " |          client_cert='/path/to/clientcert.pem',\n",
      " |          # PEM formatted SSL client key\n",
      " |          client_key='/path/to/clientkey.pem'\n",
      " |      )\n",
      " |  \n",
      " |  Alternatively you can use RFC-1738 formatted URLs, as long as they are not\n",
      " |  in conflict with other options::\n",
      " |  \n",
      " |      es = Elasticsearch(\n",
      " |          [\n",
      " |              'http://user:secret@localhost:9200/',\n",
      " |              'https://user:secret@other_host:443/production'\n",
      " |          ],\n",
      " |          verify_certs=True\n",
      " |      )\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hosts=None, transport_class=<class 'elasticsearch.transport.Transport'>, **kwargs)\n",
      " |      :arg hosts: list of nodes we should connect to. Node should be a\n",
      " |          dictionary ({\"host\": \"localhost\", \"port\": 9200}), the entire dictionary\n",
      " |          will be passed to the :class:`~elasticsearch.Connection` class as\n",
      " |          kwargs, or a string in the format of ``host[:port]`` which will be\n",
      " |          translated to a dictionary automatically.  If no value is given the\n",
      " |          :class:`~elasticsearch.Urllib3HttpConnection` class defaults will be used.\n",
      " |      \n",
      " |      :arg transport_class: :class:`~elasticsearch.Transport` subclass to use.\n",
      " |      \n",
      " |      :arg kwargs: any additional arguments will be passed on to the\n",
      " |          :class:`~elasticsearch.Transport` class and, subsequently, to the\n",
      " |          :class:`~elasticsearch.Connection` instances.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  bulk(self, body, index=None, doc_type=None, params=None)\n",
      " |      Perform many index/delete operations in a single API call.\n",
      " |      \n",
      " |      See the :func:`~elasticsearch.helpers.bulk` helper function for a more\n",
      " |      friendly API.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html>`_\n",
      " |      \n",
      " |      :arg body: The operation definition and data (action-data pairs),\n",
      " |          separated by newlines\n",
      " |      :arg index: Default index for items which don't provide one\n",
      " |      :arg doc_type: Default document type for items which don't provide one\n",
      " |      :arg _source: True or false to return the _source field or not, or\n",
      " |          default list of fields to return, can be overridden on each sub-\n",
      " |          request\n",
      " |      :arg _source_exclude: Default list of fields to exclude from the\n",
      " |          returned _source field, can be overridden on each sub-request\n",
      " |      :arg _source_include: Default list of fields to extract and return from\n",
      " |          the _source field, can be overridden on each sub-request\n",
      " |      :arg fields: Default comma-separated list of fields to return in the\n",
      " |          response for updates, can be overridden on each sub-request\n",
      " |      :arg pipeline: The pipeline id to preprocess incoming documents with\n",
      " |      :arg refresh: If `true` then refresh the effected shards to make this\n",
      " |          operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default)\n",
      " |          then do nothing with refreshes., valid choices are: 'true', 'false',\n",
      " |          'wait_for'\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg timeout: Explicit operation timeout\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the bulk operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the\n",
      " |          total number of copies for the shard (number of replicas + 1)\n",
      " |  \n",
      " |  clear_scroll(self, scroll_id=None, body=None, params=None)\n",
      " |      Clear the scroll request created by specifying the scroll parameter to\n",
      " |      search.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html>`_\n",
      " |      \n",
      " |      :arg scroll_id: A comma-separated list of scroll IDs to clear\n",
      " |      :arg body: A comma-separated list of scroll IDs to clear if none was\n",
      " |          specified via the scroll_id parameter\n",
      " |  \n",
      " |  count(self, index=None, doc_type=None, body=None, params=None)\n",
      " |      Execute a query and get the number of matches for that query.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-count.html>`_\n",
      " |      \n",
      " |      :arg index: A comma-separated list of indices to restrict the results\n",
      " |      :arg doc_type: A comma-separated list of types to restrict the results\n",
      " |      :arg body: A query to restrict the results specified with the Query DSL\n",
      " |          (optional)\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix queries\n",
      " |          should be analyzed (default: false)\n",
      " |      :arg analyzer: The analyzer to use for the query string\n",
      " |      :arg default_operator: The default operator for query string query (AND\n",
      " |          or OR), default 'OR', valid choices are: 'AND', 'OR'\n",
      " |      :arg df: The field to use as default where no field prefix is given in\n",
      " |          the query string\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg lenient: Specify whether format-based query failures (such as\n",
      " |          providing text to a numeric field) should be ignored\n",
      " |      :arg lowercase_expanded_terms: Specify whether query terms should be\n",
      " |          lowercased\n",
      " |      :arg min_score: Include only documents with a specific `_score` value in\n",
      " |          the result\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg q: Query in the Lucene query string syntax\n",
      " |      :arg routing: Specific routing value\n",
      " |  \n",
      " |  count_percolate(self, index, doc_type, id=None, body=None, params=None)\n",
      " |      The percolator allows to register queries against an index, and then\n",
      " |      send percolate requests which include a doc, and getting back the\n",
      " |      queries that match on that doc out of the set of registered queries.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-percolate.html>`_\n",
      " |      \n",
      " |      :arg index: The index of the document being count percolated.\n",
      " |      :arg doc_type: The type of the document being count percolated.\n",
      " |      :arg id: Substitute the document in the request body with a document\n",
      " |          that is known by the specified id. On top of the id, the index and\n",
      " |          type parameter will be used to retrieve the document from within the\n",
      " |          cluster.\n",
      " |      :arg body: The count percolator request definition using the percolate\n",
      " |          DSL\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg percolate_index: The index to count percolate the document into.\n",
      " |          Defaults to index.\n",
      " |      :arg percolate_type: The type to count percolate document into. Defaults\n",
      " |          to type.\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg routing: A comma-separated list of specific routing values\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |  \n",
      " |  create(self, index, doc_type, id, body, params=None)\n",
      " |      Adds a typed JSON document in a specific index, making it searchable.\n",
      " |      Behind the scenes this method calls index(..., op_type='create')\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document\n",
      " |      :arg id: Document ID\n",
      " |      :arg body: The document\n",
      " |      :arg parent: ID of the parent document\n",
      " |      :arg pipeline: The pipeline id to preprocess incoming documents with\n",
      " |      :arg refresh: If `true` then refresh the affected shards to make this\n",
      " |          operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default)\n",
      " |          then do nothing with refreshes., valid choices are: u'true',\n",
      " |          u'false', u'wait_for'\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg timeout: Explicit operation timeout\n",
      " |      :arg timestamp: Explicit timestamp for the document\n",
      " |      :arg ttl: Expiration time for the document\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are:\n",
      " |          u'internal', u'external', u'external_gte', u'force'\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the index operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the\n",
      " |          total number of copies for the shard (number of replicas + 1)\n",
      " |  \n",
      " |  delete(self, index, doc_type, id, params=None)\n",
      " |      Delete a typed JSON document from a specific index based on its id.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document\n",
      " |      :arg id: The document ID\n",
      " |      :arg parent: ID of parent document\n",
      " |      :arg refresh: If `true` then refresh the effected shards to make this\n",
      " |          operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default)\n",
      " |          then do nothing with refreshes., valid choices are: 'true', 'false',\n",
      " |          'wait_for'\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg timeout: Explicit operation timeout\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the delete operation. Defaults to\n",
      " |          1, meaning the primary shard only. Set to `all` for all shard\n",
      " |          copies, otherwise set to any non-negative value less than or equal\n",
      " |          to the total number of copies for the shard (number of replicas + 1)\n",
      " |  \n",
      " |  delete_by_query(self, index, body, doc_type=None, params=None)\n",
      " |      Delete all documents matching a query.\n",
      " |      `<https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html>`_\n",
      " |      \n",
      " |      :arg index: A comma-separated list of index names to search; use `_all`\n",
      " |          or empty string to perform the operation on all indices\n",
      " |      :arg body: The search definition using the Query DSL\n",
      " |      :arg doc_type: A comma-separated list of document types to search; leave\n",
      " |          empty to perform the operation on all types\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix queries\n",
      " |          should be analyzed (default: false)\n",
      " |      :arg analyzer: The analyzer to use for the query string\n",
      " |      :arg conflicts: What to do when the delete-by-query hits version\n",
      " |          conflicts?, default 'abort', valid choices are: 'abort', 'proceed'\n",
      " |      :arg default_operator: The default operator for query string query (AND\n",
      " |          or OR), default 'OR', valid choices are: 'AND', 'OR'\n",
      " |      :arg df: The field to use as default where no field prefix is given in\n",
      " |          the query string\n",
      " |      :arg docvalue_fields: A comma-separated list of fields to return as the\n",
      " |          docvalue representation of a field for each hit\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg explain: Specify whether to return detailed information about score\n",
      " |          computation as part of a hit\n",
      " |      :arg from\\_: Starting offset (default: 0)\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg lenient: Specify whether format-based query failures (such as\n",
      " |          providing text to a numeric field) should be ignored\n",
      " |      :arg lowercase_expanded_terms: Specify whether query terms should be\n",
      " |          lowercased\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg q: Query in the Lucene query string syntax\n",
      " |      :arg refresh: Should the effected indexes be refreshed?\n",
      " |      :arg request_cache: Specify if request cache should be used for this\n",
      " |          request or not, defaults to index level setting\n",
      " |      :arg requests_per_second: The throttle for this request in sub-requests\n",
      " |          per second. -1 means set no throttle., default 0\n",
      " |      :arg routing: A comma-separated list of specific routing values\n",
      " |      :arg scroll: Specify how long a consistent view of the index should be\n",
      " |          maintained for scrolled search\n",
      " |      :arg scroll_size: Size on the scroll request powering the\n",
      " |          update_by_query\n",
      " |      :arg search_timeout: Explicit timeout for each search request. Defaults\n",
      " |          to no timeout.\n",
      " |      :arg search_type: Search operation type, valid choices are:\n",
      " |          'query_then_fetch', 'dfs_query_then_fetch'\n",
      " |      :arg size: Number of hits to return (default: 10)\n",
      " |      :arg sort: A comma-separated list of <field>:<direction> pairs\n",
      " |      :arg stats: Specific 'tag' of the request for logging and statistical\n",
      " |          purposes\n",
      " |      :arg stored_fields: A comma-separated list of stored fields to return as\n",
      " |          part of a hit\n",
      " |      :arg suggest_field: Specify which field to use for suggestions\n",
      " |      :arg suggest_mode: Specify suggest mode, default 'missing', valid\n",
      " |          choices are: 'missing', 'popular', 'always'\n",
      " |      :arg suggest_size: How many suggestions to return in response\n",
      " |      :arg suggest_text: The source text for which the suggestions should be\n",
      " |          returned\n",
      " |      :arg terminate_after: The maximum number of documents to collect for\n",
      " |          each shard, upon reaching which the query execution will terminate\n",
      " |          early.\n",
      " |      :arg timeout: Time each individual bulk request should wait for shards\n",
      " |          that are unavailable., default '1m'\n",
      " |      :arg track_scores: Whether to calculate and return scores even if they\n",
      " |          are not used for sorting\n",
      " |      :arg version: Specify whether to return document version as part of a\n",
      " |          hit\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the delete by query operation.\n",
      " |          Defaults to 1, meaning the primary shard only. Set to `all` for all\n",
      " |          shard copies, otherwise set to any non-negative value less than or\n",
      " |          equal to the total number of copies for the shard (number of\n",
      " |          replicas + 1)\n",
      " |      :arg wait_for_completion: Should the request should block until the\n",
      " |          delete-by-query is complete., default False\n",
      " |  \n",
      " |  delete_script(self, lang, id, params=None)\n",
      " |      Remove a stored script from elasticsearch.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html>`_\n",
      " |      \n",
      " |      :arg lang: Script language\n",
      " |      :arg id: Script ID\n",
      " |  \n",
      " |  delete_template(self, id, params=None)\n",
      " |      Delete a search template.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html>`_\n",
      " |      \n",
      " |      :arg id: Template ID\n",
      " |  \n",
      " |  exists(self, index, doc_type, id, params=None)\n",
      " |      Returns a boolean indicating whether or not given document exists in Elasticsearch.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document (use `_all` to fetch the first\n",
      " |          document matching the ID across all types)\n",
      " |      :arg id: The document ID\n",
      " |      :arg parent: The ID of the parent document\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg realtime: Specify whether to perform the operation in realtime or\n",
      " |          search mode\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation\n",
      " |      :arg routing: Specific routing value\n",
      " |  \n",
      " |  explain(self, index, doc_type, id, body=None, params=None)\n",
      " |      The explain api computes a score explanation for a query and a specific\n",
      " |      document. This can give useful feedback whether a document matches or\n",
      " |      didn't match a specific query.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-explain.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document\n",
      " |      :arg id: The document ID\n",
      " |      :arg body: The query definition using the Query DSL\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg analyze_wildcard: Specify whether wildcards and prefix queries in\n",
      " |          the query string query should be analyzed (default: false)\n",
      " |      :arg analyzer: The analyzer for the query string query\n",
      " |      :arg default_operator: The default operator for query string query (AND\n",
      " |          or OR), default 'OR', valid choices are: 'AND', 'OR'\n",
      " |      :arg df: The default field for query string query (default: _all)\n",
      " |      :arg lenient: Specify whether format-based query failures (such as\n",
      " |          providing text to a numeric field) should be ignored\n",
      " |      :arg lowercase_expanded_terms: Specify whether query terms should be\n",
      " |          lowercased\n",
      " |      :arg parent: The ID of the parent document\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg q: Query in the Lucene query string syntax\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg stored_fields: A comma-separated list of stored fields to return in\n",
      " |          the response\n",
      " |  \n",
      " |  field_stats(self, index=None, body=None, params=None)\n",
      " |      The field stats api allows one to find statistical properties of a\n",
      " |      field without executing a search, but looking up measurements that are\n",
      " |      natively available in the Lucene index.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-field-stats.html>`_\n",
      " |      \n",
      " |      :arg index: A comma-separated list of index names; use `_all` or empty\n",
      " |          string to perform the operation on all indices\n",
      " |      :arg body: Field json objects containing the name and optionally a range\n",
      " |          to filter out indices result, that have results outside the defined\n",
      " |          bounds\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg fields: A comma-separated list of fields for to get field\n",
      " |          statistics for (min value, max value, and more)\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg level: Defines if field stats should be returned on a per index\n",
      " |          level or on a cluster wide level, default 'cluster', valid choices\n",
      " |          are: 'indices', 'cluster'\n",
      " |  \n",
      " |  get(self, index, id, doc_type='_all', params=None)\n",
      " |      Get a typed JSON document from the index based on its id.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document (use `_all` to fetch the first\n",
      " |          document matching the ID across all types)\n",
      " |      :arg id: The document ID\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg parent: The ID of the parent document\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg realtime: Specify whether to perform the operation in realtime or\n",
      " |          search mode\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg stored_fields: A comma-separated list of stored fields to return in\n",
      " |          the response\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |  \n",
      " |  get_script(self, lang, id, params=None)\n",
      " |      Retrieve a script from the API.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html>`_\n",
      " |      \n",
      " |      :arg lang: Script language\n",
      " |      :arg id: Script ID\n",
      " |  \n",
      " |  get_source(self, index, doc_type, id, params=None)\n",
      " |      Get the source of a document by it's index, type and id.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document; use `_all` to fetch the first\n",
      " |          document matching the ID across all types\n",
      " |      :arg id: The document ID\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg parent: The ID of the parent document\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg realtime: Specify whether to perform the operation in realtime or\n",
      " |          search mode\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |  \n",
      " |  get_template(self, id, params=None)\n",
      " |      Retrieve a search template.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html>`_\n",
      " |      \n",
      " |      :arg id: Template ID\n",
      " |  \n",
      " |  index(self, index, doc_type, body, id=None, params=None)\n",
      " |      Adds or updates a typed JSON document in a specific index, making it searchable.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document\n",
      " |      :arg body: The document\n",
      " |      :arg id: Document ID\n",
      " |      :arg op_type: Explicit operation type, default 'index', valid choices\n",
      " |          are: 'index', 'create'\n",
      " |      :arg parent: ID of the parent document\n",
      " |      :arg pipeline: The pipeline id to preprocess incoming documents with\n",
      " |      :arg refresh: If `true` then refresh the affected shards to make this\n",
      " |          operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default)\n",
      " |          then do nothing with refreshes., valid choices are: u'true',\n",
      " |          u'false', u'wait_for'\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg timeout: Explicit operation timeout\n",
      " |      :arg timestamp: Explicit timestamp for the document\n",
      " |      :arg ttl: Expiration time for the document\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the index operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the\n",
      " |          total number of copies for the shard (number of replicas + 1)\n",
      " |  \n",
      " |  info(self, params=None)\n",
      " |      Get the basic info from the current cluster.\n",
      " |      `<http://www.elastic.co/guide/>`_\n",
      " |  \n",
      " |  mget(self, body, index=None, doc_type=None, params=None)\n",
      " |      Get multiple documents based on an index, type (optional) and ids.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-multi-get.html>`_\n",
      " |      \n",
      " |      :arg body: Document identifiers; can be either `docs` (containing full\n",
      " |          document information) or `ids` (when index and type is provided in\n",
      " |          the URL.\n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg realtime: Specify whether to perform the operation in realtime or\n",
      " |          search mode\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation\n",
      " |      :arg stored_fields: A comma-separated list of stored fields to return in\n",
      " |          the response\n",
      " |  \n",
      " |  mpercolate(self, body, index=None, doc_type=None, params=None)\n",
      " |      The percolator allows to register queries against an index, and then\n",
      " |      send percolate requests which include a doc, and getting back the\n",
      " |      queries that match on that doc out of the set of registered queries.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-percolate.html>`_\n",
      " |      \n",
      " |      :arg body: The percolate request definitions (header & body pair),\n",
      " |          separated by newlines\n",
      " |      :arg index: The index of the document being count percolated to use as\n",
      " |          default\n",
      " |      :arg doc_type: The type of the document being percolated to use as\n",
      " |          default.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |  \n",
      " |  msearch(self, body, index=None, doc_type=None, params=None)\n",
      " |      Execute several search requests within the same API.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-multi-search.html>`_\n",
      " |      \n",
      " |      :arg body: The request definitions (metadata-search request definition\n",
      " |          pairs), separated by newlines\n",
      " |      :arg index: A comma-separated list of index names to use as default\n",
      " |      :arg doc_type: A comma-separated list of document types to use as\n",
      " |          default\n",
      " |      :arg max_concurrent_searches: Controls the maximum number of concurrent\n",
      " |          searches the multi search api will execute\n",
      " |      :arg search_type: Search operation type, valid choices are:\n",
      " |          'query_then_fetch', 'query_and_fetch', 'dfs_query_then_fetch',\n",
      " |          'dfs_query_and_fetch'\n",
      " |  \n",
      " |  msearch_template(self, body, index=None, doc_type=None, params=None)\n",
      " |      The /_search/template endpoint allows to use the mustache language to\n",
      " |      pre render search requests, before they are executed and fill existing\n",
      " |      templates with template parameters.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html>`_\n",
      " |      \n",
      " |      :arg body: The request definitions (metadata-search request definition\n",
      " |          pairs), separated by newlines\n",
      " |      :arg index: A comma-separated list of index names to use as default\n",
      " |      :arg doc_type: A comma-separated list of document types to use as\n",
      " |          default\n",
      " |      :arg search_type: Search operation type, valid choices are:\n",
      " |          'query_then_fetch', 'query_and_fetch', 'dfs_query_then_fetch',\n",
      " |          'dfs_query_and_fetch'\n",
      " |  \n",
      " |  mtermvectors(self, index=None, doc_type=None, body=None, params=None)\n",
      " |      Multi termvectors API allows to get multiple termvectors based on an\n",
      " |      index, type and id.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-multi-termvectors.html>`_\n",
      " |      \n",
      " |      :arg index: The index in which the document resides.\n",
      " |      :arg doc_type: The type of the document.\n",
      " |      :arg body: Define ids, documents, parameters or a list of parameters per\n",
      " |          document here. You must at least provide a list of document ids. See\n",
      " |          documentation.\n",
      " |      :arg field_statistics: Specifies if document count, sum of document\n",
      " |          frequencies and sum of total term frequencies should be returned.\n",
      " |          Applies to all returned documents unless otherwise specified in body\n",
      " |          \"params\" or \"docs\"., default True\n",
      " |      :arg fields: A comma-separated list of fields to return. Applies to all\n",
      " |          returned documents unless otherwise specified in body \"params\" or\n",
      " |          \"docs\".\n",
      " |      :arg ids: A comma-separated list of documents ids. You must define ids\n",
      " |          as parameter or set \"ids\" or \"docs\" in the request body\n",
      " |      :arg offsets: Specifies if term offsets should be returned. Applies to\n",
      " |          all returned documents unless otherwise specified in body \"params\"\n",
      " |          or \"docs\"., default True\n",
      " |      :arg parent: Parent id of documents. Applies to all returned documents\n",
      " |          unless otherwise specified in body \"params\" or \"docs\".\n",
      " |      :arg payloads: Specifies if term payloads should be returned. Applies to\n",
      " |          all returned documents unless otherwise specified in body \"params\"\n",
      " |          or \"docs\"., default True\n",
      " |      :arg positions: Specifies if term positions should be returned. Applies\n",
      " |          to all returned documents unless otherwise specified in body\n",
      " |          \"params\" or \"docs\"., default True\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random) .Applies to all returned documents\n",
      " |          unless otherwise specified in body \"params\" or \"docs\".\n",
      " |      :arg realtime: Specifies if requests are real-time as opposed to near-\n",
      " |          real-time (default: true).\n",
      " |      :arg routing: Specific routing value. Applies to all returned documents\n",
      " |          unless otherwise specified in body \"params\" or \"docs\".\n",
      " |      :arg term_statistics: Specifies if total term frequency and document\n",
      " |          frequency should be returned. Applies to all returned documents\n",
      " |          unless otherwise specified in body \"params\" or \"docs\"., default\n",
      " |          False\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |  \n",
      " |  percolate(self, index, doc_type, id=None, body=None, params=None)\n",
      " |      The percolator allows to register queries against an index, and then\n",
      " |      send percolate requests which include a doc, and getting back the\n",
      " |      queries that match on that doc out of the set of registered queries.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-percolate.html>`_\n",
      " |      \n",
      " |      :arg index: The index of the document being percolated.\n",
      " |      :arg doc_type: The type of the document being percolated.\n",
      " |      :arg id: Substitute the document in the request body with a document\n",
      " |          that is known by the specified id. On top of the id, the index and\n",
      " |          type parameter will be used to retrieve the document from within the\n",
      " |          cluster.\n",
      " |      :arg body: The percolator request definition using the percolate DSL\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg percolate_format: Return an array of matching query IDs instead of\n",
      " |          objects, valid choices are: 'ids'\n",
      " |      :arg percolate_index: The index to percolate the document into. Defaults\n",
      " |          to index.\n",
      " |      :arg percolate_preference: Which shard to prefer when executing the\n",
      " |          percolate request.\n",
      " |      :arg percolate_routing: The routing value to use when percolating the\n",
      " |          existing document.\n",
      " |      :arg percolate_type: The type to percolate document into. Defaults to\n",
      " |          type.\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg routing: A comma-separated list of specific routing values\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |  \n",
      " |  ping(self, params=None)\n",
      " |      Returns True if the cluster is up, False otherwise.\n",
      " |      `<http://www.elastic.co/guide/>`_\n",
      " |  \n",
      " |  put_script(self, lang, id, body, params=None)\n",
      " |      Create a script in given language with specified ID.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html>`_\n",
      " |      \n",
      " |      :arg lang: Script language\n",
      " |      :arg id: Script ID\n",
      " |      :arg body: The document\n",
      " |  \n",
      " |  put_template(self, id, body, params=None)\n",
      " |      Create a search template.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html>`_\n",
      " |      \n",
      " |      :arg id: Template ID\n",
      " |      :arg body: The document\n",
      " |  \n",
      " |  reindex(self, body, params=None)\n",
      " |      Reindex all documents from one index to another.\n",
      " |      `<https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html>`_\n",
      " |      \n",
      " |      :arg body: The search definition using the Query DSL and the prototype\n",
      " |          for the index request.\n",
      " |      :arg refresh: Should the effected indexes be refreshed?\n",
      " |      :arg requests_per_second: The throttle to set on this request in sub-\n",
      " |          requests per second. -1 means set no throttle as does \"unlimited\"\n",
      " |          which is the only non-float this accepts., default 0\n",
      " |      :arg timeout: Time each individual bulk request should wait for shards\n",
      " |          that are unavailable., default '1m'\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the reindex operation. Defaults to\n",
      " |          1, meaning the primary shard only. Set to `all` for all shard\n",
      " |          copies, otherwise set to any non-negative value less than or equal\n",
      " |          to the total number of copies for the shard (number of replicas + 1)\n",
      " |      :arg wait_for_completion: Should the request should block until the\n",
      " |          reindex is complete., default False\n",
      " |  \n",
      " |  reindex_rethrottle(self, task_id=None, params=None)\n",
      " |      Change the value of ``requests_per_second`` of a running ``reindex`` task.\n",
      " |      `<https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html>`_\n",
      " |      \n",
      " |      :arg task_id: The task id to rethrottle\n",
      " |      :arg requests_per_second: The throttle to set on this request in\n",
      " |          floating sub-requests per second. -1 means set no throttle.\n",
      " |  \n",
      " |  render_search_template(self, id=None, body=None, params=None)\n",
      " |      `<http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-template.html>`_\n",
      " |      \n",
      " |      :arg id: The id of the stored search template\n",
      " |      :arg body: The search definition template and its params\n",
      " |  \n",
      " |  scroll(self, scroll_id=None, body=None, params=None)\n",
      " |      Scroll a search request created by specifying the scroll parameter.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html>`_\n",
      " |      \n",
      " |      :arg scroll_id: The scroll ID\n",
      " |      :arg body: The scroll ID if not passed by URL or query parameter.\n",
      " |      :arg scroll: Specify how long a consistent view of the index should be\n",
      " |          maintained for scrolled search\n",
      " |  \n",
      " |  search(self, index=None, doc_type=None, body=None, params=None)\n",
      " |      Execute a search query and get back search hits that match the query.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html>`_\n",
      " |      \n",
      " |      :arg index: A comma-separated list of index names to search; use `_all`\n",
      " |          or empty string to perform the operation on all indices\n",
      " |      :arg doc_type: A comma-separated list of document types to search; leave\n",
      " |          empty to perform the operation on all types\n",
      " |      :arg body: The search definition using the Query DSL\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix queries\n",
      " |          should be analyzed (default: false)\n",
      " |      :arg analyzer: The analyzer to use for the query string\n",
      " |      :arg default_operator: The default operator for query string query (AND\n",
      " |          or OR), default 'OR', valid choices are: 'AND', 'OR'\n",
      " |      :arg df: The field to use as default where no field prefix is given in\n",
      " |          the query string\n",
      " |      :arg docvalue_fields: A comma-separated list of fields to return as the\n",
      " |          docvalue representation of a field for each hit\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg explain: Specify whether to return detailed information about score\n",
      " |          computation as part of a hit\n",
      " |      :arg fielddata_fields: A comma-separated list of fields to return as the\n",
      " |          docvalue representation of a field for each hit\n",
      " |      :arg from\\_: Starting offset (default: 0)\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg lenient: Specify whether format-based query failures (such as\n",
      " |          providing text to a numeric field) should be ignored\n",
      " |      :arg lowercase_expanded_terms: Specify whether query terms should be\n",
      " |          lowercased\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg q: Query in the Lucene query string syntax\n",
      " |      :arg request_cache: Specify if request cache should be used for this\n",
      " |          request or not, defaults to index level setting\n",
      " |      :arg routing: A comma-separated list of specific routing values\n",
      " |      :arg scroll: Specify how long a consistent view of the index should be\n",
      " |          maintained for scrolled search\n",
      " |      :arg search_type: Search operation type, valid choices are:\n",
      " |          'query_then_fetch', 'dfs_query_then_fetch'\n",
      " |      :arg size: Number of hits to return (default: 10)\n",
      " |      :arg sort: A comma-separated list of <field>:<direction> pairs\n",
      " |      :arg stats: Specific 'tag' of the request for logging and statistical\n",
      " |          purposes\n",
      " |      :arg stored_fields: A comma-separated list of stored fields to return as\n",
      " |          part of a hit\n",
      " |      :arg suggest_field: Specify which field to use for suggestions\n",
      " |      :arg suggest_mode: Specify suggest mode, default 'missing', valid\n",
      " |          choices are: 'missing', 'popular', 'always'\n",
      " |      :arg suggest_size: How many suggestions to return in response\n",
      " |      :arg suggest_text: The source text for which the suggestions should be\n",
      " |          returned\n",
      " |      :arg terminate_after: The maximum number of documents to collect for\n",
      " |          each shard, upon reaching which the query execution will terminate\n",
      " |          early.\n",
      " |      :arg timeout: Explicit operation timeout\n",
      " |      :arg track_scores: Whether to calculate and return scores even if they\n",
      " |          are not used for sorting\n",
      " |      :arg version: Specify whether to return document version as part of a\n",
      " |          hit\n",
      " |  \n",
      " |  search_shards(self, index=None, doc_type=None, params=None)\n",
      " |      The search shards api returns the indices and shards that a search\n",
      " |      request would be executed against. This can give useful feedback for working\n",
      " |      out issues or planning optimizations with routing and shard preferences.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-shards.html>`_\n",
      " |      \n",
      " |      :arg index: A comma-separated list of index names to search; use `_all`\n",
      " |          or empty string to perform the operation on all indices\n",
      " |      :arg doc_type: A comma-separated list of document types to search; leave\n",
      " |          empty to perform the operation on all types\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg local: Return local information, do not retrieve the state from\n",
      " |          master node (default: false)\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg routing: Specific routing value\n",
      " |  \n",
      " |  search_template(self, index=None, doc_type=None, body=None, params=None)\n",
      " |      A query that accepts a query template and a map of key/value pairs to\n",
      " |      fill in template parameters.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html>`_\n",
      " |      \n",
      " |      :arg index: A comma-separated list of index names to search; use `_all`\n",
      " |          or empty string to perform the operation on all indices\n",
      " |      :arg doc_type: A comma-separated list of document types to search; leave\n",
      " |          empty to perform the operation on all types\n",
      " |      :arg body: The search definition template and its params\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg routing: A comma-separated list of specific routing values\n",
      " |      :arg scroll: Specify how long a consistent view of the index should be\n",
      " |          maintained for scrolled search\n",
      " |      :arg search_type: Search operation type, valid choices are:\n",
      " |          'query_then_fetch', 'query_and_fetch', 'dfs_query_then_fetch',\n",
      " |          'dfs_query_and_fetch'\n",
      " |  \n",
      " |  suggest(self, body, index=None, params=None)\n",
      " |      The suggest feature suggests similar looking terms based on a provided\n",
      " |      text by using a suggester.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html>`_\n",
      " |      \n",
      " |      :arg body: The request definition\n",
      " |      :arg index: A comma-separated list of index names to restrict the\n",
      " |          operation; use `_all` or empty string to perform the operation on\n",
      " |          all indices\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg routing: Specific routing value\n",
      " |  \n",
      " |  termvectors(self, index, doc_type, id=None, body=None, params=None)\n",
      " |      Returns information and statistics on terms in the fields of a\n",
      " |      particular document. The document could be stored in the index or\n",
      " |      artificially provided by the user (Added in 1.4). Note that for\n",
      " |      documents stored in the index, this is a near realtime API as the term\n",
      " |      vectors are not available until the next refresh.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-termvectors.html>`_\n",
      " |      \n",
      " |      :arg index: The index in which the document resides.\n",
      " |      :arg doc_type: The type of the document.\n",
      " |      :arg id: The id of the document, when not specified a doc param should\n",
      " |          be supplied.\n",
      " |      :arg body: Define parameters and or supply a document to get termvectors\n",
      " |          for. See documentation.\n",
      " |      :arg field_statistics: Specifies if document count, sum of document\n",
      " |          frequencies and sum of total term frequencies should be returned.,\n",
      " |          default True\n",
      " |      :arg fields: A comma-separated list of fields to return.\n",
      " |      :arg offsets: Specifies if term offsets should be returned., default\n",
      " |          True\n",
      " |      :arg parent: Parent id of documents.\n",
      " |      :arg payloads: Specifies if term payloads should be returned., default\n",
      " |          True\n",
      " |      :arg positions: Specifies if term positions should be returned., default\n",
      " |          True\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random).\n",
      " |      :arg realtime: Specifies if request is real-time as opposed to near-\n",
      " |          real-time (default: true).\n",
      " |      :arg routing: Specific routing value.\n",
      " |      :arg term_statistics: Specifies if total term frequency and document\n",
      " |          frequency should be returned., default False\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'external', 'external_gte', 'force'\n",
      " |  \n",
      " |  update(self, index, doc_type, id, body=None, params=None)\n",
      " |      Update a document based on a script or partial data provided.\n",
      " |      `<http://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html>`_\n",
      " |      \n",
      " |      :arg index: The name of the index\n",
      " |      :arg doc_type: The type of the document\n",
      " |      :arg id: Document ID\n",
      " |      :arg body: The request definition using either `script` or partial `doc`\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg fields: A comma-separated list of fields to return in the response\n",
      " |      :arg lang: The script language (default: groovy)\n",
      " |      :arg parent: ID of the parent document. Is is only used for routing and\n",
      " |          when for the upsert request\n",
      " |      :arg refresh: If `true` then refresh the effected shards to make this\n",
      " |          operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default)\n",
      " |          then do nothing with refreshes., valid choices are: 'true', 'false',\n",
      " |          'wait_for'\n",
      " |      :arg retry_on_conflict: Specify how many times should the operation be\n",
      " |          retried when a conflict occurs (default: 0)\n",
      " |      :arg routing: Specific routing value\n",
      " |      :arg timeout: Explicit operation timeout\n",
      " |      :arg timestamp: Explicit timestamp for the document\n",
      " |      :arg ttl: Expiration time for the document\n",
      " |      :arg version: Explicit version number for concurrency control\n",
      " |      :arg version_type: Specific version type, valid choices are: 'internal',\n",
      " |          'force'\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the update operation. Defaults to\n",
      " |          1, meaning the primary shard only. Set to `all` for all shard\n",
      " |          copies, otherwise set to any non-negative value less than or equal\n",
      " |          to the total number of copies for the shard (number of replicas + 1)\n",
      " |  \n",
      " |  update_by_query(self, index, doc_type=None, body=None, params=None)\n",
      " |      Perform an update on all documents matching a query.\n",
      " |      `<https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update-by-query.html>`_\n",
      " |      \n",
      " |      :arg index: A comma-separated list of index names to search; use `_all`\n",
      " |          or empty string to perform the operation on all indices\n",
      " |      :arg doc_type: A comma-separated list of document types to search; leave\n",
      " |          empty to perform the operation on all types\n",
      " |      :arg body: The search definition using the Query DSL\n",
      " |      :arg _source: True or false to return the _source field or not, or a\n",
      " |          list of fields to return\n",
      " |      :arg _source_exclude: A list of fields to exclude from the returned\n",
      " |          _source field\n",
      " |      :arg _source_include: A list of fields to extract and return from the\n",
      " |          _source field\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified)\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix queries\n",
      " |          should be analyzed (default: false)\n",
      " |      :arg analyzer: The analyzer to use for the query string\n",
      " |      :arg conflicts: What to do when the reindex hits version conflicts?,\n",
      " |          default 'abort', valid choices are: 'abort', 'proceed'\n",
      " |      :arg default_operator: The default operator for query string query (AND\n",
      " |          or OR), default 'OR', valid choices are: 'AND', 'OR'\n",
      " |      :arg df: The field to use as default where no field prefix is given in\n",
      " |          the query string\n",
      " |      :arg docvalue_fields: A comma-separated list of fields to return as the\n",
      " |          docvalue representation of a field for each hit\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to concrete\n",
      " |          indices that are open, closed or both., default 'open', valid\n",
      " |          choices are: 'open', 'closed', 'none', 'all'\n",
      " |      :arg explain: Specify whether to return detailed information about score\n",
      " |          computation as part of a hit\n",
      " |      :arg fielddata_fields: A comma-separated list of fields to return as the\n",
      " |          docvalue representation of a field for each hit\n",
      " |      :arg from\\_: Starting offset (default: 0)\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices should be\n",
      " |          ignored when unavailable (missing or closed)\n",
      " |      :arg lenient: Specify whether format-based query failures (such as\n",
      " |          providing text to a numeric field) should be ignored\n",
      " |      :arg lowercase_expanded_terms: Specify whether query terms should be\n",
      " |          lowercased\n",
      " |      :arg pipeline: Ingest pipeline to set on index requests made by this\n",
      " |          action. (default: none)\n",
      " |      :arg preference: Specify the node or shard the operation should be\n",
      " |          performed on (default: random)\n",
      " |      :arg q: Query in the Lucene query string syntax\n",
      " |      :arg refresh: Should the effected indexes be refreshed?\n",
      " |      :arg request_cache: Specify if request cache should be used for this\n",
      " |          request or not, defaults to index level setting\n",
      " |      :arg requests_per_second: The throttle to set on this request in sub-\n",
      " |          requests per second. -1 means set no throttle as does \"unlimited\"\n",
      " |          which is the only non-float this accepts., default 0\n",
      " |      :arg routing: A comma-separated list of specific routing values\n",
      " |      :arg scroll: Specify how long a consistent view of the index should be\n",
      " |          maintained for scrolled search\n",
      " |      :arg scroll_size: Size on the scroll request powering the\n",
      " |          update_by_query\n",
      " |      :arg search_timeout: Explicit timeout for each search request. Defaults\n",
      " |          to no timeout.\n",
      " |      :arg search_type: Search operation type, valid choices are:\n",
      " |          'query_then_fetch', 'dfs_query_then_fetch'\n",
      " |      :arg size: Number of hits to return (default: 10)\n",
      " |      :arg sort: A comma-separated list of <field>:<direction> pairs\n",
      " |      :arg stats: Specific 'tag' of the request for logging and statistical\n",
      " |          purposes\n",
      " |      :arg stored_fields: A comma-separated list of stored fields to return as\n",
      " |          part of a hit\n",
      " |      :arg suggest_field: Specify which field to use for suggestions\n",
      " |      :arg suggest_mode: Specify suggest mode, default 'missing', valid\n",
      " |          choices are: 'missing', 'popular', 'always'\n",
      " |      :arg suggest_size: How many suggestions to return in response\n",
      " |      :arg suggest_text: The source text for which the suggestions should be\n",
      " |          returned\n",
      " |      :arg terminate_after: The maximum number of documents to collect for\n",
      " |          each shard, upon reaching which the query execution will terminate\n",
      " |          early.\n",
      " |      :arg timeout: Time each individual bulk request should wait for shards\n",
      " |          that are unavailable., default '1m'\n",
      " |      :arg track_scores: Whether to calculate and return scores even if they\n",
      " |          are not used for sorting\n",
      " |      :arg version: Specify whether to return document version as part of a\n",
      " |          hit\n",
      " |      :arg version_type: Should the document increment the version number\n",
      " |          (internal) on hit or not (reindex)\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies that must\n",
      " |          be active before proceeding with the update by query operation.\n",
      " |          Defaults to 1, meaning the primary shard only. Set to `all` for all\n",
      " |          shard copies, otherwise set to any non-negative value less than or\n",
      " |          equal to the total number of copies for the shard (number of\n",
      " |          replicas + 1)\n",
      " |      :arg wait_for_completion: Should the request should block until the\n",
      " |          reindex is complete., default False\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Elasticsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102 davidu\n",
      "48443 jeffbarr\n",
      "658323 danphilpott\n",
      "795029 samj\n",
      "810641 oncee\n",
      "813697 mckeay\n",
      "1088411 gattaca\n",
      "3107271 randybias\n",
      "3247471 paulfroberts\n",
      "4905551 masontech\n",
      "7025212 jack_daniel\n",
      "8236572 ryanaraine\n",
      "8917142 dakami\n",
      "9956632 mroesch\n",
      "10351232 MikeWiacek\n",
      "11443182 scamboy\n",
      "11687162 andrewsmhay\n",
      "11791512 gcluley\n",
      "12219832 lmwalsh2112\n",
      "12692452 anton_chuvakin\n",
      "13089682 pdp\n",
      "13275122 McGrewSecurity\n",
      "13850552 raffaelmarty\n",
      "14090906 WeldPond\n",
      "14118608 dmkravets\n",
      "14174808 jjx\n",
      "14181505 jeremiahg\n",
      "14244412 roblemos\n",
      "14277681 BrianHonan\n",
      "14293266 helpnetsecurity\n",
      "14333690 DavidLinthicum\n",
      "14415986 agent0x0\n",
      "14666934 kevinmitnick\n",
      "14669471 csoghoian\n",
      "14780493 lennyzeltser\n",
      "14803061 lptacek\n",
      "14924745 thedarktangent\n",
      "15040971 mattjay\n",
      "15270591 smallbizprivacy\n",
      "15447522 k8em0\n",
      "15581551 mdowd\n",
      "15589731 thierryzoller\n",
      "15637093 RSnake\n",
      "15637965 ah8r\n",
      "15655289 carnal0wnage\n",
      "15757132 edskoudis\n",
      "15943215 BillBrenner70\n",
      "16103879 sarapeters\n",
      "16626073 SteveD3\n",
      "16730420 SophosLabs\n",
      "16935717 SecurityExpert\n",
      "17226373 hal_pomeranz\n",
      "17464103 ihackstuff\n",
      "17604714 benrothke\n",
      "17767238 taosecurity\n",
      "17775619 beist\n",
      "18174265 PariseauTT\n",
      "18213516 DanRaywood\n",
      "18252252 Mike_Mimoso\n",
      "18476766 schneierblog\n",
      "18766698 bpiatt\n",
      "18783289 adamshostack\n",
      "18789893 threatpost\n",
      "18983429 thegrugq\n",
      "19206209 McAfee_Labs\n",
      "20492381 chetwisniewski\n",
      "20537779 irongeek_adc\n",
      "21501463 justin_foster\n",
      "21650546 Shpantzer\n",
      "22790881 briankrebs\n",
      "23566038 mikko\n",
      "23791544 CesareGarlati\n",
      "28494014 jonathanmayer\n",
      "33658564 sethr\n",
      "38956896 drericcole\n",
      "39262054 RazorEQX\n",
      "40072739 GovInfoSecurity\n",
      "40706825 joshcorman\n",
      "40713876 jamesrbuk\n",
      "41260072 timstrazz\n",
      "43130563 securityshell\n",
      "44666078 lcamtuf\n",
      "51845510 RudhirSharan\n",
      "57279114 GeoffCasely\n",
      "64677310 Dejan_Kosutic\n",
      "65845659 0xcharlie\n",
      "83342567 security_expert\n",
      "86064583 SecurityEditor\n",
      "97450156 cesarcer\n",
      "98145567 helenaedelson\n",
      "100361060 kevtownsend\n",
      "118059149 virusbtn\n",
      "132778684 duckblog\n",
      "135907568 ryancbarnett\n",
      "161038997 sophos_news\n",
      "187289213 SecurityScholar\n",
      "192976110 zdFYRashid\n",
      "198365324 NakedSecurity\n",
      "219152305 julian0liver\n",
      "263917895 switch_d\n",
      "297856522 e_kaspersky\n",
      "302716548 ZDNetCharlie\n",
      "312383587 jmgosney\n",
      "390189754 therealsaumil\n",
      "405658492 securityaffairs\n",
      "412360172 WillardNBC6\n",
      "842951166 Aliya_NextGov\n",
      "1609424114 pauldotcom\n",
      "2788383706 sintheticlabs\n",
      "3103951909 teamandirc\n",
      "3109130999 danchodanchev\n",
      "3187792019 danchodanchev\n",
      "3208415403 tonybradleybsg\n"
     ]
    }
   ],
   "source": [
    "#uidscreen_name\n",
    "response = es.search(\n",
    "    index=\"twitter2\",\n",
    "    doc_type=\"user\",\n",
    "    body={\n",
    "            \"query\": {\n",
    "                    \"match_all\": {}\n",
    "            },\n",
    "            \"size\":200,\n",
    "            \"sort\":{\"uid\":\"asc\"}\n",
    "            \n",
    "        }\n",
    ")\n",
    "#print (json.dumps(response,indent=2))\n",
    "tuid_list=[]\n",
    "tname_list=[]\n",
    "for user in response['hits']['hits']:\n",
    "   tuid_list.append(user['_source']['uid'])\n",
    "   tname_list.append(user['_source']['screen_name'])\n",
    "   print (user['_source']['uid'],user['_source']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elasticsearch:GET http://localhost:9200/twitter2/_search [status:200 request:0.006s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter? Ans: 100\n",
      "Tweets? Ans: 4562\n"
     ]
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"twitter2\",\n",
    "    body={\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\":[\n",
    "                        {\"match\":{\"tweet.text\":\"vulnerability\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"cve\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"Exploit\"}}\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1\n",
    "                }\n",
    "            },              \n",
    "            \"aggs\": {\n",
    "                \"tweet\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"uid\",\n",
    "                        \"size\": 800000\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    }\n",
    ")\n",
    "#print (json.dumps(response,indent=2))\n",
    "twitters=[]\n",
    "tweets=0\n",
    "for tweet in response['aggregations']['tweet']['buckets']:\n",
    "    for k in range(len(tuid_list)):\n",
    "        if tuid_list[k]==tweet['key']:\n",
    "            tname=tname_list[k]\n",
    "#            print (tname)\n",
    "    twitters.append(tweet['key'])\n",
    "    tweets += tweet['doc_count']\n",
    "#    print (\"[Twitter]:\",tname,' [Keyword Hints]:',tweet['doc_count'])\n",
    "print()\n",
    "print (\"Twitter? Ans:\",len(twitters))\n",
    "print (\"Tweets? Ans:\",tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "from bokeh.sampledata.autompg import autompg as df\n",
    "from bokeh.layouts import row,widgetbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elasticsearch:GET http://localhost:9200/twitter2/_search [status:200 request:0.022s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Month]: 2008-04  [Keyword Hints]: 1\n",
      "[Month]: 2008-05  [Keyword Hints]: 4\n",
      "[Month]: 2008-07  [Keyword Hints]: 3\n",
      "[Month]: 2008-08  [Keyword Hints]: 1\n",
      "[Month]: 2009-03  [Keyword Hints]: 3\n",
      "[Month]: 2009-04  [Keyword Hints]: 1\n",
      "[Month]: 2009-05  [Keyword Hints]: 2\n",
      "[Month]: 2009-06  [Keyword Hints]: 2\n",
      "[Month]: 2009-07  [Keyword Hints]: 6\n",
      "[Month]: 2009-08  [Keyword Hints]: 1\n",
      "[Month]: 2009-09  [Keyword Hints]: 3\n",
      "[Month]: 2009-10  [Keyword Hints]: 3\n",
      "[Month]: 2009-11  [Keyword Hints]: 9\n",
      "[Month]: 2009-12  [Keyword Hints]: 4\n",
      "[Month]: 2010-01  [Keyword Hints]: 9\n",
      "[Month]: 2010-02  [Keyword Hints]: 6\n",
      "[Month]: 2010-03  [Keyword Hints]: 8\n",
      "[Month]: 2010-04  [Keyword Hints]: 5\n",
      "[Month]: 2010-05  [Keyword Hints]: 8\n",
      "[Month]: 2010-06  [Keyword Hints]: 11\n",
      "[Month]: 2010-07  [Keyword Hints]: 7\n",
      "[Month]: 2010-08  [Keyword Hints]: 16\n",
      "[Month]: 2010-09  [Keyword Hints]: 19\n",
      "[Month]: 2010-10  [Keyword Hints]: 6\n",
      "[Month]: 2010-11  [Keyword Hints]: 10\n",
      "[Month]: 2010-12  [Keyword Hints]: 7\n",
      "[Month]: 2011-01  [Keyword Hints]: 10\n",
      "[Month]: 2011-02  [Keyword Hints]: 16\n",
      "[Month]: 2011-03  [Keyword Hints]: 7\n",
      "[Month]: 2011-04  [Keyword Hints]: 9\n",
      "[Month]: 2011-05  [Keyword Hints]: 10\n",
      "[Month]: 2011-06  [Keyword Hints]: 8\n",
      "[Month]: 2011-07  [Keyword Hints]: 7\n",
      "[Month]: 2011-08  [Keyword Hints]: 10\n",
      "[Month]: 2011-09  [Keyword Hints]: 15\n",
      "[Month]: 2011-10  [Keyword Hints]: 8\n",
      "[Month]: 2011-11  [Keyword Hints]: 10\n",
      "[Month]: 2011-12  [Keyword Hints]: 7\n",
      "[Month]: 2012-01  [Keyword Hints]: 15\n",
      "[Month]: 2012-02  [Keyword Hints]: 17\n",
      "[Month]: 2012-03  [Keyword Hints]: 32\n",
      "[Month]: 2012-04  [Keyword Hints]: 14\n",
      "[Month]: 2012-05  [Keyword Hints]: 28\n",
      "[Month]: 2012-06  [Keyword Hints]: 30\n",
      "[Month]: 2012-07  [Keyword Hints]: 7\n",
      "[Month]: 2012-08  [Keyword Hints]: 16\n",
      "[Month]: 2012-09  [Keyword Hints]: 21\n",
      "[Month]: 2012-10  [Keyword Hints]: 28\n",
      "[Month]: 2012-11  [Keyword Hints]: 30\n",
      "[Month]: 2012-12  [Keyword Hints]: 23\n",
      "[Month]: 2013-01  [Keyword Hints]: 52\n",
      "[Month]: 2013-02  [Keyword Hints]: 62\n",
      "[Month]: 2013-03  [Keyword Hints]: 41\n",
      "[Month]: 2013-04  [Keyword Hints]: 42\n",
      "[Month]: 2013-05  [Keyword Hints]: 42\n",
      "[Month]: 2013-06  [Keyword Hints]: 43\n",
      "[Month]: 2013-07  [Keyword Hints]: 43\n",
      "[Month]: 2013-08  [Keyword Hints]: 52\n",
      "[Month]: 2013-09  [Keyword Hints]: 56\n",
      "[Month]: 2013-10  [Keyword Hints]: 88\n",
      "[Month]: 2013-11  [Keyword Hints]: 55\n",
      "[Month]: 2013-12  [Keyword Hints]: 52\n",
      "[Month]: 2014-01  [Keyword Hints]: 102\n",
      "[Month]: 2014-02  [Keyword Hints]: 100\n",
      "[Month]: 2014-03  [Keyword Hints]: 86\n",
      "[Month]: 2014-04  [Keyword Hints]: 158\n",
      "[Month]: 2014-05  [Keyword Hints]: 88\n",
      "[Month]: 2014-06  [Keyword Hints]: 111\n",
      "[Month]: 2014-07  [Keyword Hints]: 104\n",
      "[Month]: 2014-08  [Keyword Hints]: 83\n",
      "[Month]: 2014-09  [Keyword Hints]: 195\n",
      "[Month]: 2014-10  [Keyword Hints]: 181\n",
      "[Month]: 2014-11  [Keyword Hints]: 120\n",
      "[Month]: 2014-12  [Keyword Hints]: 93\n",
      "[Month]: 2015-01  [Keyword Hints]: 219\n",
      "[Month]: 2015-02  [Keyword Hints]: 205\n",
      "[Month]: 2015-03  [Keyword Hints]: 465\n",
      "[Month]: 2015-04  [Keyword Hints]: 294\n",
      "[Month]: 2015-05  [Keyword Hints]: 283\n",
      "[Month]: 2015-06  [Keyword Hints]: 307\n",
      "[Month]: 2015-07  [Keyword Hints]: 207\n",
      "\n",
      "4562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bokeh.core.state:Session output file 'bar1.html' already exists, will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"twitter2\",\n",
    "    body={\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\":[\n",
    "                        {\"match\":{\"tweet.text\":\"vulnerability\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"cve\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"Exploit\"}}\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1\n",
    "                }\n",
    "            },\n",
    "            \"aggs\": {\n",
    "                \"tweet\": {\n",
    "                    \"date_histogram\": {\n",
    "                         \"field\": \"created_at\",\n",
    "                         \"interval\": '1M'\n",
    "                    },\n",
    "                    \"aggs\": {\n",
    "                        \"tweet\": {\n",
    "                            \"terms\": {\n",
    "                                \"field\": \"uid\",\n",
    "                                \"size\": 200\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    ")\n",
    "#print (json.dumps(response,indent=2))\n",
    "month=[]\n",
    "tweets=[]\n",
    "#tcount=0\n",
    "for tweet in response['aggregations']['tweet']['buckets']:\n",
    "    mon=time.strftime('%Y-%m',(time.strptime(tweet['key_as_string'],'%a %b %d %H:%M:%S %z %Y')))\n",
    "    print (\"[Month]:\",mon,' [Keyword Hints]:',tweet['doc_count'])\n",
    "    month.append(mon)\n",
    "    tweets.append(tweet['doc_count'])\n",
    "#    tcount+=tweet['doc_count']\n",
    "print()\n",
    "#print (tcount)\n",
    "bar1 = Bar(tweets,plot_width=1500)\n",
    "\n",
    "output_file(\"bar1.html\")\n",
    "show(bar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elasticsearch:GET http://localhost:9200/twitter2/_search [status:200 request:0.018s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Month]: 2008-04 Twitter = 1 Tweets = 1\n",
      "[Month]: 2008-05 Twitter = 1 Tweets = 4\n",
      "[Month]: 2008-07 Twitter = 3 Tweets = 3\n",
      "[Month]: 2008-08 Twitter = 1 Tweets = 1\n",
      "[Month]: 2009-03 Twitter = 2 Tweets = 3\n",
      "[Month]: 2009-04 Twitter = 1 Tweets = 1\n",
      "[Month]: 2009-05 Twitter = 2 Tweets = 2\n",
      "[Month]: 2009-06 Twitter = 2 Tweets = 2\n",
      "[Month]: 2009-07 Twitter = 3 Tweets = 6\n",
      "[Month]: 2009-08 Twitter = 1 Tweets = 1\n",
      "[Month]: 2009-09 Twitter = 2 Tweets = 3\n",
      "[Month]: 2009-10 Twitter = 2 Tweets = 3\n",
      "[Month]: 2009-11 Twitter = 6 Tweets = 9\n",
      "[Month]: 2009-12 Twitter = 3 Tweets = 4\n",
      "[Month]: 2010-01 Twitter = 5 Tweets = 9\n",
      "[Month]: 2010-02 Twitter = 3 Tweets = 6\n",
      "[Month]: 2010-03 Twitter = 5 Tweets = 8\n",
      "[Month]: 2010-04 Twitter = 4 Tweets = 5\n",
      "[Month]: 2010-05 Twitter = 4 Tweets = 8\n",
      "[Month]: 2010-06 Twitter = 5 Tweets = 11\n",
      "[Month]: 2010-07 Twitter = 6 Tweets = 7\n",
      "[Month]: 2010-08 Twitter = 10 Tweets = 16\n",
      "[Month]: 2010-09 Twitter = 9 Tweets = 19\n",
      "[Month]: 2010-10 Twitter = 5 Tweets = 6\n",
      "[Month]: 2010-11 Twitter = 5 Tweets = 10\n",
      "[Month]: 2010-12 Twitter = 3 Tweets = 7\n",
      "[Month]: 2011-01 Twitter = 7 Tweets = 10\n",
      "[Month]: 2011-02 Twitter = 6 Tweets = 16\n",
      "[Month]: 2011-03 Twitter = 4 Tweets = 7\n",
      "[Month]: 2011-04 Twitter = 5 Tweets = 9\n",
      "[Month]: 2011-05 Twitter = 8 Tweets = 10\n",
      "[Month]: 2011-06 Twitter = 7 Tweets = 8\n",
      "[Month]: 2011-07 Twitter = 6 Tweets = 7\n",
      "[Month]: 2011-08 Twitter = 7 Tweets = 10\n",
      "[Month]: 2011-09 Twitter = 8 Tweets = 15\n",
      "[Month]: 2011-10 Twitter = 5 Tweets = 8\n",
      "[Month]: 2011-11 Twitter = 9 Tweets = 10\n",
      "[Month]: 2011-12 Twitter = 5 Tweets = 7\n",
      "[Month]: 2012-01 Twitter = 8 Tweets = 15\n",
      "[Month]: 2012-02 Twitter = 10 Tweets = 17\n",
      "[Month]: 2012-03 Twitter = 8 Tweets = 32\n",
      "[Month]: 2012-04 Twitter = 9 Tweets = 14\n",
      "[Month]: 2012-05 Twitter = 17 Tweets = 28\n",
      "[Month]: 2012-06 Twitter = 14 Tweets = 30\n",
      "[Month]: 2012-07 Twitter = 6 Tweets = 7\n",
      "[Month]: 2012-08 Twitter = 10 Tweets = 16\n",
      "[Month]: 2012-09 Twitter = 12 Tweets = 21\n",
      "[Month]: 2012-10 Twitter = 13 Tweets = 28\n",
      "[Month]: 2012-11 Twitter = 15 Tweets = 30\n",
      "[Month]: 2012-12 Twitter = 13 Tweets = 23\n",
      "[Month]: 2013-01 Twitter = 22 Tweets = 52\n",
      "[Month]: 2013-02 Twitter = 21 Tweets = 62\n",
      "[Month]: 2013-03 Twitter = 21 Tweets = 41\n",
      "[Month]: 2013-04 Twitter = 20 Tweets = 42\n",
      "[Month]: 2013-05 Twitter = 22 Tweets = 42\n",
      "[Month]: 2013-06 Twitter = 17 Tweets = 43\n",
      "[Month]: 2013-07 Twitter = 18 Tweets = 43\n",
      "[Month]: 2013-08 Twitter = 23 Tweets = 52\n",
      "[Month]: 2013-09 Twitter = 21 Tweets = 56\n",
      "[Month]: 2013-10 Twitter = 26 Tweets = 88\n",
      "[Month]: 2013-11 Twitter = 18 Tweets = 55\n",
      "[Month]: 2013-12 Twitter = 22 Tweets = 52\n",
      "[Month]: 2014-01 Twitter = 28 Tweets = 102\n",
      "[Month]: 2014-02 Twitter = 29 Tweets = 100\n",
      "[Month]: 2014-03 Twitter = 25 Tweets = 86\n",
      "[Month]: 2014-04 Twitter = 48 Tweets = 158\n",
      "[Month]: 2014-05 Twitter = 36 Tweets = 88\n",
      "[Month]: 2014-06 Twitter = 34 Tweets = 111\n",
      "[Month]: 2014-07 Twitter = 32 Tweets = 104\n",
      "[Month]: 2014-08 Twitter = 39 Tweets = 83\n",
      "[Month]: 2014-09 Twitter = 51 Tweets = 195\n",
      "[Month]: 2014-10 Twitter = 55 Tweets = 181\n",
      "[Month]: 2014-11 Twitter = 36 Tweets = 120\n",
      "[Month]: 2014-12 Twitter = 40 Tweets = 93\n",
      "[Month]: 2015-01 Twitter = 55 Tweets = 219\n",
      "[Month]: 2015-02 Twitter = 47 Tweets = 205\n",
      "[Month]: 2015-03 Twitter = 50 Tweets = 465\n",
      "[Month]: 2015-04 Twitter = 42 Tweets = 294\n",
      "[Month]: 2015-05 Twitter = 60 Tweets = 283\n",
      "[Month]: 2015-06 Twitter = 54 Tweets = 307\n",
      "[Month]: 2015-07 Twitter = 37 Tweets = 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bokeh.core.state:Session output file 'bar.html' already exists, will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"twitter2\",\n",
    "    body={\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\":[\n",
    "                        {\"match\":{\"tweet.text\":\"vulnerability\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"cve\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"Exploit\"}}\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1\n",
    "                }\n",
    "            },\n",
    "            \"aggs\": {\n",
    "                \"tweet\": {\n",
    "                    \"date_histogram\": {\n",
    "                         \"field\": \"created_at\",\n",
    "                         \"interval\": '1M'\n",
    "                    },\n",
    "                    \"aggs\": {\n",
    "                        \"tweet\": {\n",
    "                            \"terms\": {\n",
    "                                \"field\": \"uid\",\n",
    "                                \"size\": 200\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    ")\n",
    "#print (json.dumps(response,indent=2))\n",
    "twitters=[]\n",
    "num_twitters=[]\n",
    "tweets=[]\n",
    "#for tweet in response['aggregations']['tweet']['buckets']:\n",
    "for l in range(len(response['aggregations']['tweet']['buckets'])):        \n",
    "    for m in range(len(response['aggregations']['tweet']['buckets'][l]['tweet']['buckets'])):\n",
    "        twitters.append(response['aggregations']['tweet']['buckets'][l]['tweet']['buckets'][m]['key'])\n",
    "    mon=time.strftime('%Y-%m',(time.strptime(response['aggregations']['tweet']['buckets'][l]\n",
    "                                             ['key_as_string'],'%a %b %d %H:%M:%S %z %Y')))\n",
    "    print (\"[Month]:\",mon,\"Twitter =\",len(twitters),\n",
    "           \"Tweets =\",response['aggregations']['tweet']['buckets'][l]['doc_count'])\n",
    "    num_twitters.append(len(twitters))\n",
    "    tweets.append(response['aggregations']['tweet']['buckets'][l]['doc_count'])\n",
    "    twitters=[]\n",
    "bar1 = Bar(tweets,plot_width=1500)    \n",
    "bar2 = Bar(num_twitters,plot_width=1500)\n",
    "\n",
    "output_file(\"bar.html\")\n",
    "show(row(bar1,bar2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elasticsearch:GET http://localhost:9200/twitter2/_search [status:200 request:0.274s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLTweets= 1033 , 22.64%\n",
      "URLTweets= 3529 , 77.36%\n"
     ]
    }
   ],
   "source": [
    "from bokeh.charts import Donut, show, output_notebook, vplot\n",
    "from bokeh.charts.utils import df_from_json\n",
    "import pandas as pd\n",
    "\n",
    "response = es.search(\n",
    "    index=\"twitter2\",\n",
    "    body={\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\":[\n",
    "                        {\"match\":{\"tweet.text\":\"vulnerability\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"cve\"}},\n",
    "                        {\"match\":{\"tweet.text\":\"Exploit\"}}\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1\n",
    "                }\n",
    "            },\n",
    "            \"from\": 0,\n",
    "            \"size\": 800000\n",
    "    }\n",
    ")\n",
    "#print (json.dumps(response,indent=2))\n",
    "nurl=0\n",
    "for tweet in response['hits']['hits']:\n",
    "    if (tweet['_source']['entities']['urls']) == []:\n",
    "        nurl=nurl+1\n",
    "t_total=len(response['hits']['hits'])\n",
    "print ('URLTweets=',nurl,',',format(nurl/t_total, '.2%'))\n",
    "print ('URLTweets=',t_total-nurl,',',format((t_total-nurl)/t_total, '.2%'))\n",
    "\n",
    "\n",
    "\n",
    "d=Donut(pd.Series([nurl , t_total-nurl] , index = ['URL  '+format(nurl/t_total, '.2%'),'URL  '+format((t_total-nurl)/t_total, '.2%')]))\n",
    "show(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elasticsearch:GET http://localhost:9200/twitter2/_search [status:200 request:0.020s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Month]: 2008-07\n",
      "raffaelmarty : 1 \n",
      "[Month]: 2009-11\n",
      "agent0x0 : 1 \n",
      "[Month]: 2010-01\n",
      "beist : 1 \n",
      "[Month]: 2010-03\n",
      "cesarcer : 1 \n",
      "[Month]: 2010-06\n",
      "beist : 2 \n",
      "[Month]: 2010-07\n",
      "cesarcer : 1 \n",
      "[Month]: 2010-09\n",
      "beist : 1 \n",
      "McAfee_Labs : 1 \n",
      "chetwisniewski : 1 \n",
      "[Month]: 2010-10\n",
      "beist : 1 \n",
      "[Month]: 2010-12\n",
      "cesarcer : 1 \n",
      "[Month]: 2011-01\n",
      "cesarcer : 1 \n",
      "[Month]: 2011-02\n",
      "chetwisniewski : 1 \n",
      "[Month]: 2011-04\n",
      "chetwisniewski : 1 \n",
      "cesarcer : 1 \n",
      "[Month]: 2011-07\n",
      "agent0x0 : 1 \n",
      "[Month]: 2011-09\n",
      "cesarcer : 1 \n",
      "ryancbarnett : 1 \n",
      "[Month]: 2011-10\n",
      "cesarcer : 2 \n",
      "[Month]: 2011-12\n",
      "chetwisniewski : 1 \n",
      "[Month]: 2012-01\n",
      "ryancbarnett : 4 \n",
      "mdowd : 1 \n",
      "[Month]: 2012-02\n",
      "mdowd : 1 \n",
      "chetwisniewski : 1 \n",
      "cesarcer : 1 \n",
      "[Month]: 2012-03\n",
      "ryanaraine : 1 \n",
      "[Month]: 2012-04\n",
      "ryanaraine : 1 \n",
      "McAfee_Labs : 1 \n",
      "[Month]: 2012-05\n",
      "e_kaspersky : 1 \n",
      "[Month]: 2012-06\n",
      "ryanaraine : 2 \n",
      "[Month]: 2012-07\n",
      "chetwisniewski : 2 \n",
      "[Month]: 2012-08\n",
      "McAfee_Labs : 2 \n",
      "chetwisniewski : 2 \n",
      "[Month]: 2013-01\n",
      "mdowd : 1 \n",
      "justin_foster : 1 \n",
      "[Month]: 2013-02\n",
      "ryanaraine : 2 \n",
      "paulfroberts : 1 \n",
      "[Month]: 2013-04\n",
      "beist : 1 \n",
      "briankrebs : 1 \n",
      "securityshell : 1 \n",
      "SecurityScholar : 1 \n",
      "[Month]: 2013-05\n",
      "adamshostack : 1 \n",
      "securityshell : 1 \n",
      "duckblog : 1 \n",
      "NakedSecurity : 1 \n",
      "[Month]: 2013-06\n",
      "securityshell : 4 \n",
      "carnal0wnage : 1 \n",
      "beist : 1 \n",
      "SecurityScholar : 1 \n",
      "[Month]: 2013-07\n",
      "jmgosney : 1 \n",
      "[Month]: 2013-08\n",
      "agent0x0 : 1 \n",
      "carnal0wnage : 1 \n",
      "securityshell : 1 \n",
      "[Month]: 2013-09\n",
      "securityshell : 2 \n",
      "thierryzoller : 1 \n",
      "McAfee_Labs : 1 \n",
      "[Month]: 2013-10\n",
      "thierryzoller : 4 \n",
      "SophosLabs : 2 \n",
      "securityshell : 2 \n",
      "duckblog : 2 \n",
      "NakedSecurity : 2 \n",
      "jjx : 1 \n",
      "thedarktangent : 1 \n",
      "hal_pomeranz : 1 \n",
      "[Month]: 2013-11\n",
      "RazorEQX : 4 \n",
      "ryanaraine : 1 \n",
      "lennyzeltser : 1 \n",
      "thedarktangent : 1 \n",
      "thierryzoller : 1 \n",
      "SecurityExpert : 1 \n",
      "adamshostack : 1 \n",
      "McAfee_Labs : 1 \n",
      "securityshell : 1 \n",
      "cesarcer : 1 \n",
      "duckblog : 1 \n",
      "[Month]: 2013-12\n",
      "thierryzoller : 2 \n",
      "edskoudis : 1 \n",
      "McAfee_Labs : 1 \n",
      "[Month]: 2014-01\n",
      "carnal0wnage : 2 \n",
      "adamshostack : 2 \n",
      "securityshell : 1 \n",
      "[Month]: 2014-02\n",
      "securityshell : 4 \n",
      "RazorEQX : 3 \n",
      "McAfee_Labs : 2 \n",
      "ryancbarnett : 2 \n",
      "ryanaraine : 1 \n",
      "WeldPond : 1 \n",
      "thierryzoller : 1 \n",
      "carnal0wnage : 1 \n",
      "beist : 1 \n",
      "therealsaumil : 1 \n",
      "[Month]: 2014-03\n",
      "virusbtn : 7 \n",
      "thierryzoller : 3 \n",
      "securityshell : 2 \n",
      "mdowd : 1 \n",
      "RSnake : 1 \n",
      "carnal0wnage : 1 \n",
      "edskoudis : 1 \n",
      "McAfee_Labs : 1 \n",
      "RazorEQX : 1 \n",
      "ryancbarnett : 1 \n",
      "[Month]: 2014-04\n",
      "virusbtn : 4 \n",
      "securityshell : 3 \n",
      "andrewsmhay : 2 \n",
      "WeldPond : 2 \n",
      "McAfee_Labs : 2 \n",
      "agent0x0 : 1 \n",
      "thierryzoller : 1 \n",
      "taosecurity : 1 \n",
      "Mike_Mimoso : 1 \n",
      "adamshostack : 1 \n",
      "threatpost : 1 \n",
      "timstrazz : 1 \n",
      "0xcharlie : 1 \n",
      "[Month]: 2014-05\n",
      "securityshell : 3 \n",
      "virusbtn : 3 \n",
      "McAfee_Labs : 2 \n",
      "jmgosney : 2 \n",
      "therealsaumil : 2 \n",
      "thierryzoller : 1 \n",
      "carnal0wnage : 1 \n",
      "BillBrenner70 : 1 \n",
      "beist : 1 \n",
      "mikko : 1 \n",
      "[Month]: 2014-06\n",
      "thierryzoller : 4 \n",
      "virusbtn : 2 \n",
      "pdp : 1 \n",
      "mdowd : 1 \n",
      "carnal0wnage : 1 \n",
      "BillBrenner70 : 1 \n",
      "McAfee_Labs : 1 \n",
      "chetwisniewski : 1 \n",
      "timstrazz : 1 \n",
      "securityshell : 1 \n",
      "ryancbarnett : 1 \n",
      "[Month]: 2014-07\n",
      "virusbtn : 3 \n",
      "timstrazz : 2 \n",
      "securityshell : 2 \n",
      "gattaca : 1 \n",
      "jeremiahg : 1 \n",
      "thierryzoller : 1 \n",
      "[Month]: 2014-08\n",
      "virusbtn : 3 \n",
      "mattjay : 2 \n",
      "McAfee_Labs : 2 \n",
      "ryanaraine : 1 \n",
      "jeremiahg : 1 \n",
      "mdowd : 1 \n",
      "thierryzoller : 1 \n",
      "securityshell : 1 \n",
      "[Month]: 2014-09\n",
      "securityshell : 6 \n",
      "thierryzoller : 5 \n",
      "e_kaspersky : 5 \n",
      "WeldPond : 4 \n",
      "mikko : 3 \n",
      "virusbtn : 3 \n",
      "jeffbarr : 2 \n",
      "oncee : 2 \n",
      "mdowd : 2 \n",
      "BillBrenner70 : 2 \n",
      "Mike_Mimoso : 2 \n",
      "timstrazz : 2 \n",
      "0xcharlie : 2 \n",
      "danphilpott : 1 \n",
      "mckeay : 1 \n",
      "pdp : 1 \n",
      "jeremiahg : 1 \n",
      "carnal0wnage : 1 \n",
      "SteveD3 : 1 \n",
      "taosecurity : 1 \n",
      "adamshostack : 1 \n",
      "threatpost : 1 \n",
      "joshcorman : 1 \n",
      "RudhirSharan : 1 \n",
      "kevtownsend : 1 \n",
      "ryancbarnett : 1 \n",
      "julian0liver : 1 \n",
      "therealsaumil : 1 \n",
      "[Month]: 2014-10\n",
      "virusbtn : 10 \n",
      "securityshell : 9 \n",
      "BillBrenner70 : 6 \n",
      "thierryzoller : 4 \n",
      "mikko : 3 \n",
      "oncee : 2 \n",
      "WeldPond : 2 \n",
      "mckeay : 1 \n",
      "gattaca : 1 \n",
      "randybias : 1 \n",
      "pdp : 1 \n",
      "jeremiahg : 1 \n",
      "agent0x0 : 1 \n",
      "thedarktangent : 1 \n",
      "mdowd : 1 \n",
      "carnal0wnage : 1 \n",
      "SteveD3 : 1 \n",
      "taosecurity : 1 \n",
      "beist : 1 \n",
      "Mike_Mimoso : 1 \n",
      "adamshostack : 1 \n",
      "threatpost : 1 \n",
      "Shpantzer : 1 \n",
      "RazorEQX : 1 \n",
      "joshcorman : 1 \n",
      "RudhirSharan : 1 \n",
      "duckblog : 1 \n",
      "[Month]: 2014-11\n",
      "virusbtn : 8 \n",
      "securityshell : 5 \n",
      "timstrazz : 4 \n",
      "mikko : 3 \n",
      "thierryzoller : 2 \n",
      "mdowd : 1 \n",
      "carnal0wnage : 1 \n",
      "Mike_Mimoso : 1 \n",
      "threatpost : 1 \n",
      "cesarcer : 1 \n",
      "[Month]: 2014-12\n",
      "securityshell : 4 \n",
      "gcluley : 2 \n",
      "lennyzeltser : 2 \n",
      "jeffbarr : 1 \n",
      "oncee : 1 \n",
      "thedarktangent : 1 \n",
      "[Month]: 2015-01\n",
      "BillBrenner70 : 5 \n",
      "timstrazz : 5 \n",
      "securityshell : 5 \n",
      "jeffbarr : 1 \n",
      "samj : 1 \n",
      "mckeay : 1 \n",
      "andrewsmhay : 1 \n",
      "k8em0 : 1 \n",
      "thierryzoller : 1 \n",
      "SteveD3 : 1 \n",
      "Mike_Mimoso : 1 \n",
      "adamshostack : 1 \n",
      "RazorEQX : 1 \n",
      "lcamtuf : 1 \n",
      "ryancbarnett : 1 \n",
      "[Month]: 2015-02\n",
      "virusbtn : 11 \n",
      "carnal0wnage : 2 \n",
      "securityshell : 2 \n",
      "ryancbarnett : 2 \n",
      "paulfroberts : 1 \n",
      "BrianHonan : 1 \n",
      "thierryzoller : 1 \n",
      "BillBrenner70 : 1 \n",
      "beist : 1 \n",
      "adamshostack : 1 \n",
      "sethr : 1 \n",
      "timstrazz : 1 \n",
      "securityaffairs : 1 \n",
      "[Month]: 2015-03\n",
      "securityaffairs : 17 \n",
      "thegrugq : 7 \n",
      "BillBrenner70 : 5 \n",
      "thierryzoller : 3 \n",
      "virusbtn : 3 \n",
      "threatpost : 2 \n",
      "securityshell : 2 \n",
      "jmgosney : 2 \n",
      "oncee : 1 \n",
      "McGrewSecurity : 1 \n",
      "jeremiahg : 1 \n",
      "carnal0wnage : 1 \n",
      "SteveD3 : 1 \n",
      "adamshostack : 1 \n",
      "joshcorman : 1 \n",
      "timstrazz : 1 \n",
      "Dejan_Kosutic : 1 \n",
      "0xcharlie : 1 \n",
      "SecurityScholar : 1 \n",
      "[Month]: 2015-04\n",
      "thegrugq : 6 \n",
      "virusbtn : 6 \n",
      "jeremiahg : 5 \n",
      "thierryzoller : 3 \n",
      "SteveD3 : 2 \n",
      "ryancbarnett : 2 \n",
      "switch_d : 2 \n",
      "WeldPond : 1 \n",
      "k8em0 : 1 \n",
      "mdowd : 1 \n",
      "benrothke : 1 \n",
      "chetwisniewski : 1 \n",
      "mikko : 1 \n",
      "joshcorman : 1 \n",
      "securityshell : 1 \n",
      "securityaffairs : 1 \n",
      "[Month]: 2015-05\n",
      "thegrugq : 4 \n",
      "virusbtn : 3 \n",
      "mckeay : 1 \n",
      "paulfroberts : 1 \n",
      "andrewsmhay : 1 \n",
      "gcluley : 1 \n",
      "WeldPond : 1 \n",
      "jeremiahg : 1 \n",
      "mdowd : 1 \n",
      "RSnake : 1 \n",
      "SteveD3 : 1 \n",
      "beist : 1 \n",
      "CesareGarlati : 1 \n",
      "timstrazz : 1 \n",
      "0xcharlie : 1 \n",
      "securityaffairs : 1 \n",
      "[Month]: 2015-06\n",
      "securityaffairs : 34 \n",
      "thegrugq : 7 \n",
      "virusbtn : 6 \n",
      "mattjay : 2 \n",
      "securityshell : 2 \n",
      "mckeay : 1 \n",
      "dakami : 1 \n",
      "anton_chuvakin : 1 \n",
      "thierryzoller : 1 \n",
      "carnal0wnage : 1 \n",
      "BillBrenner70 : 1 \n",
      "taosecurity : 1 \n",
      "timstrazz : 1 \n",
      "e_kaspersky : 1 \n",
      "therealsaumil : 1 \n",
      "[Month]: 2015-07\n",
      "securityaffairs : 27 \n",
      "thegrugq : 10 \n",
      "BrianHonan : 4 \n",
      "BillBrenner70 : 2 \n",
      "Mike_Mimoso : 2 \n",
      "NakedSecurity : 2 \n",
      "mckeay : 1 \n",
      "gcluley : 1 \n",
      "SophosLabs : 1 \n",
      "mikko : 1 \n",
      "securityshell : 1 \n",
      "duckblog : 1 \n",
      "switch_d : 1 \n"
     ]
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"twitter2\",\n",
    "    body={\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\":{\"match\":{\"tweet.text\":\"cve\"}}\n",
    "                }\n",
    "            },\n",
    "            \"aggs\": {\n",
    "                \"tweet\": {\n",
    "                    \"date_histogram\": {\n",
    "                         \"field\": \"created_at\",\n",
    "                         \"interval\": '1M'\n",
    "                    },\n",
    "                    \"aggs\": {\n",
    "                        \"tweet\": {\n",
    "                            \"terms\": {\n",
    "                                \"field\": \"uid\",\n",
    "                                \"size\": 200\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"from\": 0,\n",
    "            \"size\": 1000\n",
    "    }\n",
    ")\n",
    "#print (json.dumps(response,indent=2))\n",
    "twitters=[]\n",
    "num_twitters=[]\n",
    "tweets=[]\n",
    "#for tweet in response['aggregations']['tweet']['buckets']:\n",
    "for l in range(len(response['aggregations']['tweet']['buckets'])):\n",
    "    mon=time.strftime('%Y-%m',(time.strptime(response['aggregations']['tweet']['buckets'][l]\n",
    "                                             ['key_as_string'],'%a %b %d %H:%M:%S %z %Y')))\n",
    "    print (\"[Month]:\",mon)\n",
    "    for m in range(len(response['aggregations']['tweet']['buckets'][l]['tweet']['buckets'])):\n",
    "        twitters.append(response['aggregations']['tweet']['buckets'][l]['tweet']['buckets'][m]['key'])\n",
    "        for k in range(len(tuid_list)):\n",
    "                if tuid_list[k]==response['aggregations']['tweet']['buckets'][l]['tweet']['buckets'][m]['key']:\n",
    "                    tname=tname_list[k]\n",
    "        print (tname,\":\",response['aggregations']['tweet']['buckets'][l]['tweet']['buckets'][m]['doc_count'],'')\n",
    "    mon=time.strftime('%Y-%m',(time.strptime(response['aggregations']['tweet']['buckets'][l]\n",
    "                                             ['key_as_string'],'%a %b %d %H:%M:%S %z %Y')))\n",
    "    #print (\"Twitter =\",len(twitters),\n",
    "    #       \"Tweets =\",response['aggregations']['tweet']['buckets'][l]['doc_count'])\n",
    "    tweets.append(response['aggregations']['tweet']['buckets'][l]['doc_count'])\n",
    "    twitters=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elasticsearch:GET http://localhost:9200/logstash*/_search [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"logstash*\",\n",
    "    body={\n",
    "          \"query\": {\n",
    "              \"range\": {\n",
    "                  \"@timestamp\": {\n",
    "                      \"gt\": \"2016-10-01T15:39:11.000Z\",\n",
    "                      \"lt\": \"2016-10-20T15:39:13.000Z\"\n",
    "                  }\n",
    "              }\n",
    "          },\n",
    "          \"from\": 0,\n",
    "          \"size\": 2\n",
    "    }\n",
    ")\n",
    "print json.dumps(response,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EveMoonshadow\n",
      "RT @Mokuri3: PPAPPPAP\n",
      "https://t.co/wvmRfQoMJ0PPAP\n",
      "\n",
      " https://t.co/MbFn7MRyHt\n",
      "2016-10-02T15:46:02.000Z\n",
      "\n",
      "\n",
      "satsuki_seimei\n",
      "RT @Mokuri3: PPAPPPAP\n",
      "https://t.co/wvmRfQoMJ0PPAP\n",
      "\n",
      " https://t.co/MbFn7MRyHt\n",
      "2016-10-02T15:47:49.000Z\n",
      "\n",
      "\n",
      "KellyKyw1010\n",
      "YiYi ...PPAP.....Go ! XDDDDD #maltese #yiyi #puppy #cute #ppap #PPAP #dog #mommyloveu #puppylove #apple #pen https://t.co/JXvqLXDa0k\n",
      "2016-10-02T15:49:07.000Z\n",
      "\n",
      "\n",
      "kiichiiiii1110\n",
      "RT @ShonanMizuno: 2\n",
      "PPAP(^o^)\n",
      "\n",
      "\n",
      "#PPAP \n",
      "# https://t.co/sBLf2f8dZA\n",
      "2016-10-02T15:39:23.000Z\n",
      "\n",
      "\n",
      "NabillahLuthfia\n",
      "RT @Daily_Namjoon: [FMV] PPAP - BTS VERSION\n",
      "\n",
      "hyukning\n",
      "#PPAP #BTS https://t.co/I1gH1LyWMa\n",
      "2016-10-02T15:39:39.000Z\n",
      "\n",
      "\n",
      "df6g_i\n",
      "RT @17_min_seun: \n",
      "PPAPver\n",
      "\n",
      "#PPAP \n",
      "#SEVENTEEN24 https://t.co/pGl6TfyWqp\n",
      "2016-10-02T15:39:48.000Z\n",
      "\n",
      "\n",
      "tohojyj_\n",
      "RT @2tv3xq5: EXO\n",
      "PPAP PPAP  \n",
      "2016-10-02T15:39:49.000Z\n",
      "\n",
      "\n",
      "_diegobbyun\n",
      "RT @FNIQEX: PPAP 555555555555555555555 #PPAP https://t.co/oJONxYQm3e\n",
      "2016-10-02T15:39:54.000Z\n",
      "\n",
      "\n",
      "Semoon94\n",
      "RT @FNIQEX: PPAP 555555555555555555555 #PPAP https://t.co/oJONxYQm3e\n",
      "2016-10-02T15:42:30.000Z\n",
      "\n",
      "\n",
      "No__249\n",
      "RT @tajtiger: This will be your new ringtone #PPAP  #PPAPchallenge #PPAP w/ @StripeyButt and @tajtiger https://t.co/mBTvXwlrBT\n",
      "2016-10-02T15:43:43.000Z\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"logstash*\",\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"must\": [\n",
    "                {\n",
    "                  \"range\": {\n",
    "                    \"@timestamp\": {\n",
    "                      \"gt\": \"2016-10-02T15:39:11.000Z\",\n",
    "                      \"lt\": \"2016-10-20T16:39:13.000Z\"\n",
    "                    }\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"term\": {\n",
    "                    \"message\": \"ppap\"\n",
    "                  }\n",
    "                }\n",
    "              ],\n",
    "              \"must_not\": [],\n",
    "              \"should\": []\n",
    "            }\n",
    "          },\n",
    "          \"from\": 0,\n",
    "          \"size\": 10\n",
    "        }\n",
    ")\n",
    "for tweet in response['hits']['hits']:\n",
    "   print tweet['_source']['user']\n",
    "   print tweet['_source']['message']\n",
    "   print tweet['_source']['@timestamp']\n",
    "   print \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\tnurqistinashah\n",
      "6\tPalmm_ExoiKON\n",
      "4\tSinobu13\n",
      "4\tkkaixi\n",
      "3\tFmsgGgl\n"
     ]
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"logstash*\",\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"term\": {\n",
    "              \"message\": \"ppap\"\n",
    "            }\n",
    "          },\n",
    "          \"aggs\": {\n",
    "            \"user\": {\n",
    "              \"terms\": {\n",
    "                \"field\": \"user.raw\",\n",
    "                \"size\": 5\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    ")\n",
    "\n",
    "#for user in response['aggregations']['user']['buckets']:\n",
    "#   print str(user['doc_count']) + \"\\t\" + user['key'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
